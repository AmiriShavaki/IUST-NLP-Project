\Section
{پیش‌پرداز‌ش‌های انجام‌شده}
{
\subsection{روش/ابزار تفکیک جملات}
{
برای تفکیک جملات از یکی از توکنایزرهای 
\lr{nltk}
استفاده کردم که با استفاده از یک مدل شبکه عصبی جملات متن ورودی را جدا می‌کند و در خروجی متن را با واحد جمله تحویل می‌دهد.

این توکنایزر در مسیر 
\lr{tokenizers/punkt/english.pickle}
از ریشه‌ی \lr{nltk}
قرار دارد.
}
\subsection{روش/ابزار تفکیک توکن‌ها/کلمات}
{
برای جدا کردن کلمات از توکنایزر مربوط به پکیج 
\lr{wordsegment}
استفاده کردم که از مدل‌های عصبی استفاده می‌کند. این پکیج همه‌ی کلمات را به حالت حروف کوچک (\lr{lowercase})
تبدیل می‌کند و علائم نگارشی را حذف می‌کند. برای تحلیل‌های بعدی و ورودی دادن به مدل اصلی از آن‌جایی بزرگی و کوچکی حروف در لحن متن تاثیر گذار است از خروجی این مرحله استفاده نخواهیم کرد و صرفا برای تحلیل‌های آماری در فاز۱ از این خروجی استفاده شده است.
}

\subsection{روش/معیارهای تمیزکردن داده}
{ 
\subsubsection{\Large جاگذاری ایموجی‌ها}
{
اگر بدون هیچ‌ پیش‌پردازشی روی ایموجی‌ها، آن‌ها را به مدل‌هایی مانند
\lr{Bert}
بدهیم، یک توکن \lr{Unknown} 
بجای همه‌ی ایموجی‌ها قرار خواهد گرفت، از طرفی حذف‌کردن ایموجی‌ها در مرحله‌ی تمیزکاری داده‌ها منطقی به نظر نمی‌رسد چون با توجه به ماهیت تسک \lr{Sentiment analysis}
وجود ایموجی و نوع ایموجی به‌ کار رفته می‌تواند سرنخ بزرگی برای تشخیص لحن نویسنده‌ی کامنت باشد. در اینجا روش به‌کار گرفته شده جاگذاری ایموجی با متن کوتاه جایگزین ایموجی است، متنی که در حد چند کلمه توصیف معنایی آن ایموجی است که به جای خود ایموجی می‌تواند به مدل، سرنخ برای تشخیص لحن نویسنده بدهد.

برای این‌کار از پکیج آماده \lr{emoji} پایتون استفاده شده است که به ازای هر ایموجی یک متن کوتاه چندکلمه‌ای آماده در اختیار می‌گذارد.
}
\subsubsection{\Large حذف کلمات پالایشی (\lr{stopwords})}
{
منظور از کلمات پالایشی کلماتی مثل 
\lr{the}
،
\lr{and}
،
\lr{is}
،
\lr{in}
،
\lr{it}
و... است.
این کلمات دربردارنده بار معنایی ارزشمندی برای تشخیص لحن نیستند و به همین دلیل با حذف آن‌ها از متن ورودی می‌توانیم حجم نویز ورودی را کم کنیم و به مدل اجازه دهیم بتواند روی کلمات کلیدی‌تر متن ورودی تمرکز کند.

برای حذف این کلمات از پکیج \lr{nltk} استفاده شده است.
}
\subsubsection{\Large بسط دادن فرم‌های کوتاه‌شده (\lr{contractions})}
{
در زبان انگلیسی به کلمات و عبارت‌های کوتاه‌شده‌ای مثل 
\lr{can't}
،
\lr{don't}
،
\lr{won't}
و
\lr{it's} فرم
\lr{contraction}
می‌گویند. با تبدیل این عبارت‌ها به فرم بسط‌ یافته می‌توانیم فرآیند 
\lr{tokenization} را بهبود بدهیم و \lr{consistency} ایجاد کنیم چون فرم بسط‌ یافته و فرم \lr{contraction} به لحاظ معنایی کاملا یکسانند بهتر است در مدل با آن‌ها یک جور مواجه شویم.

به این منظور از پکیج آماده‌ی \lr{contractions} استفاده شده است که مورد گفته شده را بطور کامل انجام می‌دهد.
}
\subsubsection{\Large حذف ارقام}
{
به نظر نمی‌رسد ارقام متن ورودی در تشخیص لحن آن بتوانند به مدل کمک کنند. پس تمام ارقام موجود در متن ورودی را حذف می‌کنیم.
}
\subsubsection{\Large حذف کاراکترهای نامربوط (کاراکترهای غیر از ارقام، حروف، فاصله و نقطه)}
{
برای حذف کاراکترهای غیر از ارقام، حروف، فاصله و نقطه از عبارت منظم (\lr{regex}) استفاده شده است.
}
\subsubsection{\Large حذف فاصله‌های اضافی}
{
در نهایت بعد از اعمال همه‌ی پیش‌پردازش‌های بالا به ترتیبی که گفته شد، همه‌ی فاصله‌های اضافی به کار رفته حذف شدند تا داده‌ها تمیز و آماده مرحله \lr{tokenization} باشند.
}
}
\newpage
\subsection{اندازه داده قبل/بعد تمیزکردن داده}
{
قبل از تمیزکردن داده:
\begin{align*}
  \csvautotabular{Tables/sizes_before_cleaning.csv}  
\end{align*}
بعد از تمیزکردن داده:
\begin{align*}
  \csvautotabular{Tables/sizes_after_cleaning.csv}  
\end{align*}
\emph{*در اینجا معیار جداکردن کلمات، کاراکتر فاصله (\lr{space}) بوده است.}
}
}